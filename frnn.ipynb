{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re  \n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import linalg as LA\n",
    "# Personal comments: deEmojify removes the emos but it (emos) might have high correlation with the sentiment and emotions\n",
    "# averaged kth Dimensional M word to reconstruct n tweeet where each tweet has l number of words, total tweets: N\n",
    "# X: NxM matrix where M is dimensional space (vocab) N number of tweets, X[c][k] represents averaged coefficients for word kth of tweet c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "def R_a_XY(X, x, y):\n",
    "    return 1-(abs(x-y)/abs(np.max(X, axis=0)-np.min(X,axis=0)))\n",
    "\n",
    "\n",
    "def R_XY(X, x, y):\n",
    "    return min(R_a_XY(X, x, y))\n",
    "\n",
    "def A(C,y_class):\n",
    "    if C == y_class:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def approximations(X, x, y, y_class, C, upper=False):\n",
    "    if upper:\n",
    "        return min(R_XY(X, x, y), A(C, y_class))\n",
    "    else:\n",
    "        return max(R_XY(X, x, y), A(C, y_class))\n",
    "\n",
    "def cosine_similarity_approximation(x, y, y_class, C, upper=False):\n",
    "    if upper:\n",
    "        #print(cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0])\n",
    "        #print('Min:',min(cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0], A(C, y_class)), A(C, y_class), C, y_class)\n",
    "        return min(cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0], A(C, y_class))\n",
    "    else:\n",
    "        #print('Max:',max(cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0], A(C, y_class)), A(C, y_class), C, y_class)\n",
    "        return max(cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0], A(C, y_class))\n",
    "\n",
    "def FRNN(X_train, y, y_class, decision_classes):\n",
    "    ta_ = 0\n",
    "    class_ = 0\n",
    "    for C in set(list(decision_classes)):\n",
    "        ind_where_class_c = np.where(decision_classes == C)\n",
    "        #print(ind_where_class_c)\n",
    "        \n",
    "        #print(X.shape, )\n",
    "        for ind in ind_where_class_c[0]:\n",
    "            #print('ind:', ind)\n",
    "            lower_approx = approximations(X_train, X_train[ind,:], y, y_class, C)\n",
    "            upper_approx = approximations(X_train, X_train[ind,:], y, y_class, C, upper=True)\n",
    "            if (lower_approx+upper_approx)/2 >= ta_:\n",
    "                class_ = C\n",
    "                ta_ = (lower_approx+upper_approx)/2\n",
    "    return class_\n",
    "\n",
    "def FRNN_cosine_sim(X_train, y, y_class, decision_classes):\n",
    "    ta_ = 0\n",
    "    class_ = 0\n",
    "    for C in set(list(decision_classes)):\n",
    "        #print(C)\n",
    "        ind_where_class_c = np.where(decision_classes == C)\n",
    "        #print(ind_where_class_c)\n",
    "        \n",
    "        #print(X.shape, )\n",
    "        for ind in ind_where_class_c[0]:\n",
    "            #print('ind:', ind)\n",
    "            lower_approx = cosine_similarity_approximation(X_train[ind,:], y, y_class, C)\n",
    "            upper_approx = cosine_similarity_approximation(X_train[ind,:], y, y_class, C, upper=True)\n",
    "            if (lower_approx+upper_approx)/2 >= ta_:\n",
    "                class_ = C\n",
    "                ta_ = (lower_approx+upper_approx)/2\n",
    "    return class_\n",
    "\n",
    "def cross_validation_split(dataset, folds=5):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "from numpy import linalg as LA\n",
    "def fuzzy_nearest_neighbour(X, x, y):\n",
    "    dist = (np.linalg.norm(y-x))**-2/(2-1)\n",
    "    sum_ = 0\n",
    "    for vec in X:\n",
    "        sum_ += (np.linalg.norm(y-vec))**-2/(2-1)\n",
    "    print(sum_, dist)\n",
    "    return dist/sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy 0.97 FRNN \n",
      "Fold 2 Accuracy 0.94 FRNN \n",
      "Fold 3 Accuracy 0.90 FRNN \n",
      "Fold 4 Accuracy 1.00 FRNN \n",
      "Fold 5 Accuracy 0.97 FRNN \n",
      "Average Accuracy 0.95 FRNN\n",
      "Std 0.03 FRNN\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    df = pd.read_csv(sys.argv[1])\n",
    "    #df = pd.read_csv('data/anger_detection_data.csv')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    tweets = list()\n",
    "    for t in df['Tweet']:\n",
    "        t = ' '.join([word for word in t.split() if word.lower() not in stop_words])\n",
    "        tweets.append(str(deEmojify(t).lower()))\n",
    "\n",
    "    tokenized = [sentence.split() for sentence in tweets]\n",
    "\n",
    "    #print(int(round(len(model.wv.vocab)/1.5)), len(model.wv.vocab))\n",
    "    model = Word2Vec(tokenized, min_count=5, size = 300, window=5, negative = 10, workers = multiprocessing.cpu_count())\n",
    "    X = np.zeros((len(df), len(model.wv.vocab)))\n",
    "    y = np.zeros((len(df), 1))\n",
    "    unknown_words = 0\n",
    "    for c, tokens in enumerate(tokenized):\n",
    "        for k, word in enumerate(tokens):\n",
    "            try:\n",
    "                X[c][k] = (np.average(model[word])+X[c][k])/2\n",
    "            except:\n",
    "                unknown_words+=1\n",
    "                continue\n",
    "        y[c][0] = int(df['Intensity Class'][c].split(\":\")[0])\n",
    "    #print('Percentage of unknown words:', unknown_words/len(model.wv.vocab))\n",
    "    folds = cross_validation_split(np.append(X, y, axis = 1))\n",
    "    frnn_acc = list()\n",
    "    for fold_counter, f in enumerate(folds):\n",
    "        data_matrix = np.asarray(f)\n",
    "        decision_classes = data_matrix[:,len(model.wv.vocab)]\n",
    "        X = np.delete(data_matrix, len(model.wv.vocab), axis=1)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, decision_classes, test_size = 0.40)\n",
    "        predictions = np.zeros((len(X_test), 1))\n",
    "        \n",
    "        for c, y in enumerate(X_test):\n",
    "            predictions[c][0] = FRNN(X_train, y, y_test[c], y_train)\n",
    "            #predictions[c][0] = FRNN_cosine_sim(X_train, y, y_test[c], y_train)\n",
    "            \n",
    "        frnn_acc.append(accuracy_score(y_test, predictions))\n",
    "        print('Fold %d Accuracy %.2f FRNN '%(fold_counter+1, accuracy_score(y_test, predictions)))\n",
    "    print('Average Accuracy %.2f FRNN'%np.average(frnn_acc))\n",
    "    print('Std %.2f FRNN'%np.std(frnn_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
